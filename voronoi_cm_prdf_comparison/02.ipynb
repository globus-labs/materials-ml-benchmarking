{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing performance of different crystal structure representations\n",
    "\n",
    "In this notebook, we'll compare the performance of three different crystal structure representations, which are Coulomb Matrix (CM), Partial Radial Distribution Function (PRDF) and Voronoi tessellation features shown in [Ward et al's paper](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.96.024104). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = pd.read_pickle('./X_cm.pkl')\n",
    "\n",
    "X_ward = pd.read_pickle('./X_ward.pkl')\n",
    "X_cm = data['coulomb matrix']\n",
    "X_prdf = pd.read_pickle('./X_prdf.pkl')\n",
    "\n",
    "y = data['delta_e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form vector descriptors using eigenvalue of CM matrix and append each vector descriptor of to make them same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cm = data['coulomb matrix']\n",
    "\n",
    "X_cm = pd.Series([np.sort(np.linalg.eigvals(s)) \\\n",
    "            for s in X_cm], X_cm.index)\n",
    "nt = max(X_cm.apply(len))\n",
    "\n",
    "XLIST = []\n",
    "for x in X_cm:\n",
    "    XLIST.append(np.append(x, np.zeros(nt - x.shape[0])))\n",
    "X_cm = np.array(XLIST)\n",
    "print (\"CM input data shape:\", X_cm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prdf = np.array(X_prdf)\n",
    "X_ward = np.nan_to_num(X_prdf, copy=True)\n",
    "print (\"PRDF input data shape:\", X_prdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ward = np.array(X_ward)\n",
    "X_ward = np.nan_to_num(X_ward, copy=True)\n",
    "print (\"Voronoi tessellation input data shape:\", X_ward.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isnan(X_prdf)), np.all(np.isfinite(X_prdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training RandomForestRegressor model\n",
    "\n",
    "A set of randomly selected 30,000 entries is used to train the model. Performance of the model is then evaluted on a distinct set of around 1000 entries. Each cross-validation test is repeated 20 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = ['ward', 'cm', 'prdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ward, X_cm, X_prdf, y = shuffle(X_ward, X_cm, X_prdf, y)\n",
    "X = {\"ward\": X_ward, \"cm\": X_cm, \"prdf\": X_prdf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training RandomForestRegressor with respective training set and compute the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats, pred, calc = dict.fromkeys(ft), dict.fromkeys(ft), dict.fromkeys(ft)\n",
    "for ft in stats:\n",
    "    stats[ft] = dict.fromkeys(['mae', 'rmse', 'r2', 'time_used'], 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ft, x in X.items():\n",
    "    for train_idx, test_idx in tqdm(ShuffleSplit(train_size=30000, test_size=1000, n_splits=20).split(x)):\n",
    "        # split dataset\n",
    "        x_train, x_test = X[ft][train_idx], X[ft][test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        print (ft, np.any(np.isnan(x_train)), np.all(np.isfinite(x_train)))\n",
    "        # compute time used to train model\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        # Use pipeline\n",
    "        Pipeline([\n",
    "                ('imputer', Imputer(missing_values='NaN', strategy='mean', axis=1)), # For the failed structures\n",
    "                ('model', RandomForestRegressor(n_estimators=100, n_jobs=-1))\n",
    "                ])\n",
    "        # train model\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        # run model\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        finish = time.perf_counter()\n",
    "        \n",
    "        # compute stats\n",
    "        stats[ft]['mae'] += mean_absolute_error(y_pred, y_test) / 20\n",
    "        stats[ft]['rmse'] += np.sqrt(mean_squared_error(y_pred, y_test)) / 20\n",
    "        stats[ft]['r2'] += r2_score(y_pred, y_test) / 20\n",
    "        stats[ft]['time_used'] += (finish - start) / 20\n",
    "        \n",
    "    # save predicted formation enthalpy at last iteration\n",
    "    pred[ft], calc[ft] = y_pred, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, sharex=True)\n",
    "\n",
    "ax1.set_title(\"CM\")\n",
    "ax2.set_title(\"PRDF\")\n",
    "ax3.set_title(\"Voronoi\")\n",
    "\n",
    "ax1.set_ylabel(\"ML $\\Delta H_f (eV/atom)$\")\n",
    "ax2.set_xlabel(\" DFT $\\Delta H_f (eV/atom)$\")\n",
    "\n",
    "ax1.scatter(calc['cm'], pred['cm'], color='g', marker='.')\n",
    "ax2.scatter(calc['prdf'], pred['prdf'], color='b', marker='.')\n",
    "ax3.scatter(calc['ward'], pred['ward'], color='r', marker='.')\n",
    "\n",
    "ax1.text(0.495, 0.026, 'MAE: {:.0f} meV/atom\\nRMSE:{:.0f} meV/atom\\n$R^2$: {:.3f}'.format(stats['cm']['mae']*1e3, stats['cm']['rmse']*1e3, stats['cm']['r2']),\n",
    "         transform=ax1.transAxes, fontsize=8,\n",
    "         bbox={'facecolor': 'w', 'edgecolor': 'k'})\n",
    "ax2.text(1.0, 0.026, 'MAE: {:.0f} meV/atom\\nRMSE:{:.0f} meV/atom\\n$R^2$: {:.3f}'.format(stats['prdf']['mae']*1e3, stats['prdf']['rmse']*1e3, stats['prdf']['r2']),\n",
    "         transform=ax1.transAxes, fontsize=8,\n",
    "         bbox={'facecolor': 'w', 'edgecolor': 'k'})\n",
    "ax3.text(1.5, 0.026, 'MAE: {:.0f} meV/atom\\nRMSE:{:.0f} meV/atom\\n$R^2$: {:.3f}'.format(stats['ward']['mae']*1e3, stats['ward']['rmse']*1e3, stats['ward']['r2']),\n",
    "         transform=ax1.transAxes, fontsize=8,\n",
    "         bbox={'facecolor': 'w', 'edgecolor': 'k'})\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
