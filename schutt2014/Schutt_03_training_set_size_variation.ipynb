{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean absolute error of DOS prediction with respect to variation in training set size \n",
    "\n",
    "In Part 3, we study how MAE of DOS prediction changes with respect to variation in training set size ([Schutt et al paper](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.89.205118))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import featurized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = pd.read_pickle('./schutt_cutoff10_binsize20.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop compounds without DOS value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:  (6174, 12085)\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(subset=['dos'])\n",
    "print (\"Shape of data: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count sp and spd systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = data['max_orbital'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition compounds into sp and spd systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=['max_orbital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_data = {'sp': data[:count['sp']], 'spd': data[count['sp']:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of sp systems:  423\n",
      "Size of spd systems:  5751\n"
     ]
    }
   ],
   "source": [
    "print (\"Size of sp systems: \", systems_data['sp'].shape[0])\n",
    "print (\"Size of spd systems: \", systems_data['spd'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify size of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_sp = [10, 50] + list(np.arange(100, systems_data['sp'].shape[0] - 100, 100))\n",
    "size_spd = [10, 100, 500] + list(np.arange(1000, systems_data['spd'].shape[0], 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_data['sp'] = systems_data['sp'].drop(['material_id', 'pretty_formula', 'structure', 'structure_obj',\n",
    "       'composition_obj', 'max_atom_num', 'max_orbital', 'dos_obj', 'volume'], 1)\n",
    "systems_data['spd'] = systems_data['spd'].drop(['material_id', 'pretty_formula', 'structure', 'structure_obj',\n",
    "       'composition_obj', 'max_atom_num', 'max_orbital', 'dos_obj', 'volume'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance of KRR models with varied training set sizes using ShuffleSplit over 30 iterations.\n",
    "- sp system testing set size: 100 \n",
    "- spd system testing set size: 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_sp = dict.fromkeys(size_sp)\n",
    "X, Y = systems_data['sp'].drop(['dos'], 1), systems_data['sp']['dos']\n",
    "for size in size_sp:\n",
    "    krr = KernelRidge(kernel='laplacian', alpha=0.0001, gamma=5e-5)\n",
    "    cv = ShuffleSplit(n_splits=30, train_size=size, test_size=100)\n",
    "    score_sp[size] = cross_val_score(krr, X, Y, cv=cv, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_spd = dict.fromkeys(size_spd)\n",
    "X, Y = systems_data['spd'].drop(['dos'], 1), systems_data['spd']['dos']\n",
    "for size in size_spd:\n",
    "    krr = KernelRidge(kernel='laplacian', alpha=1e-5, gamma=5e-5)\n",
    "    cv = ShuffleSplit(n_splits=30, train_size=size, test_size=500)\n",
    "    score_spd[size] = cross_val_score(krr, X, Y, cv=cv, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute aggregate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"sp system score:\")\n",
    "for size in score_sp:\n",
    "    print (size, \":\", score_sp[size].mean())\n",
    "print ()\n",
    "print (\"spd system score:\")\n",
    "for size in score_spd:\n",
    "    print (size, \":\", score_spd[size].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_sp = [np.abs(score_sp[size].mean()) for size in score_sp]\n",
    "mae_spd = [np.abs(score_spd[size].mean()) for size in score_spd]\n",
    "\n",
    "plt.plot(size_sp, mae_sp, color='r', marker='s', label='sp')\n",
    "plt.plot(size_spd, mae_spd, color='b', marker='^', label='spd')\n",
    "\n",
    "plt.xlabel(\"Size of training set\")\n",
    "plt.ylabel(\"MAE $(states/eV/A^3)$\")\n",
    "\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
