{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking more featurizations and ML methods in predicting formation enthalpies of compounds on OQMD dataset \n",
    "\n",
    "In this notebook, we'll compare performance of both featurizations and ML algorithms in [Ward (2016)](https://www.nature.com/articles/npjcompumats201628), [Ward (2017)](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.96.024104), [Deml (2016)](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.93.085142), [Faber (2016)](https://arxiv.org/abs/1503.07406) and [Schutt (2014)](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.89.205118) in predicting formation enthalpies of compounds, $\\Delta H_f$.\n",
    "\n",
    "Note: Run `01.ipynb`, `featurize_ward2016_dataset.ipynb` and `featurize_deml_dataset.ipynb` before this notebook!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoffet2/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/amoffet2/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning:\n",
      "\n",
      "numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymatgen as pmg\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from matminer.featurizers.structure import SineCoulombMatrix\n",
    "from matminer.featurizers.base import MultipleFeaturizer\n",
    "from matminer.featurizers import composition as cf\n",
    "from matminer.utils.conversions import str_to_composition\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.linear_model import Lars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import OQMD_ICSD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_pickle('./y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data:  (31163,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Length of data: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize dictionary to store cv prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['ward2016', 'ward2017', 'deml', 'faber', 'schutt']\n",
    "cv_test = dict.fromkeys(kernels)\n",
    "x_train, x_test, y_train, y_test = dict.fromkeys(kernels), dict.fromkeys(kernels), dict.fromkeys(kernels), dict.fromkeys(kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Faber et al (2016)\n",
    "Kernel Ridge Regression (KRR) on Sine Coulomb Matrix (SCM) featurization. Since we already have the Coulomb matrix featurized file saved in `01.ipynb`, we can directly load it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48 ms, sys: 164 ms, total: 212 ms\n",
      "Wall time: 595 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_faber = pickle.load(open(\"./X_cm.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition into training and testing set (80% training and 20% testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['faber'], x_test['faber'], y_train['faber'], y_test['faber'] = train_test_split(X_faber, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build ML model (Kernel Ridge Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr = KernelRidge()\n",
    "params = {}\n",
    "params['scm'] = [{'kernel' : ['rbf'], 'alpha' : [10**(-a) for a in range(2,6)],\n",
    "    'gamma': [1/2.0/s/s for s in (20000,40000,80000,160000,320000)]},\n",
    "    {'kernel' : ['laplacian'], 'alpha' : [10**(-a) for a in range(2,6)],\n",
    "    'gamma' : [1.0/s for s in (20000,40000,80000,160000,320000)]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpsel = GridSearchCV(krr, params['scm'], cv=KFold(5), refit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train KRR model using training set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18h 45min 33s, sys: 9h 24min 35s, total: 1d 4h 10min 9s\n",
      "Wall time: 8h 53min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    hpsel.fit(x_train['faber'], y_train['faber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign best hyperparameters to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "faber = hpsel.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    cv_test['faber'] = cross_val_predict(faber, x_test['faber'], y_test['faber'], cv=KFold(n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Ward et al (2016)  \n",
    "RandomForestRegressor on \"general purpose\" attributes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ward2016 = pd.read_pickle(\"./ward2016_featurized_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into training and testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ward2016 = df_ward2016.drop(['index', 'band_gap', 'delta_e', 'magnetic_moment', 'path', 'stability',\n",
    "       'structure', 'total_energy', 'volume_pa', 'structure_obj',\n",
    "       'composition', 'is_ICSD', 'composition_obj'], 1)\n",
    "y_ward2016 = df_ward2016['delta_e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['ward2016'], x_test['ward2016'], y_train['ward2016'], y_test['ward2016'] = train_test_split(X_ward2016, y_ward2016, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build ML model (Random Forest Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = dict(max_features=(np.linspace(0.1, 1, 10)).tolist())\n",
    "ward2016 = GridSearchCV(RandomForestRegressor(n_estimators=100),\n",
    "                        param_grid=param,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        cv=KFold(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit using training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 19s, sys: 6.79 s, total: 28min 26s\n",
      "Wall time: 28min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ward2016 = ward2016.fit(x_train['ward2016'], y_train['ward2016'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward2016 = ward2016.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict testing data using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test['ward2016'] = cross_val_predict(ward2016, x_test['ward2016'], y_test['ward2016'], cv=KFold(n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Ward et al (2017)\n",
    "\n",
    "Random Forest Regressor on Voronoi-tessellation-based crystal representation.\n",
    "\n",
    "Since the featurization takes a long time, we import the featurized pickle file ready for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ward2017 = pd.read_pickle('./X_ward.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['ward2017'], x_test['ward2017'], y_train['ward2017'], y_test['ward2017'] = train_test_split(X_ward2017, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build ML model (Random Forest Regressor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward2017 = RandomForestRegressor(n_estimators=100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 40s, sys: 2.65 s, total: 10min 43s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "ward2017 = ward2017.fit(x_train['ward2017'], y_train['ward2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test['ward2017'] = cross_val_predict(ward2017, x_test['ward2017'], y_test['ward2017'], cv=KFold(n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Deml et al\n",
    "Stepwise linear regression on composition featurized data. Since featurized data is already saved from running `featurize_deml_dataset.ipynb`, we can load data directly from that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deml = pd.read_pickle('./deml_featurized_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 4/36047 entries\n"
     ]
    }
   ],
   "source": [
    "original_count = len(df_deml)\n",
    "df_deml = df_deml[np.logical_and(df_deml['delta_e'] >= -20, df_deml['delta_e'] <= 5)].reset_index(drop=True)\n",
    "print('Removed %d/%d entries'%(original_count - len(df_deml), original_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill NaN with zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deml.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_deml = df_deml.drop(['oxidation_states', 'total_energy', 'delta_e', 'composition', 'composition_obj'], 1)\n",
    "y_deml = df_deml['delta_e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['deml'], x_test['deml'], y_train['deml'], y_test['deml'] = train_test_split(X_deml, y_deml, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build ML model (Stepwise Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "deml = GridSearchCV(Lars(), \n",
    "                    param_grid=dict(n_nonzero_coefs=(range(10, X_deml.shape[1], 20))),\n",
    "                    cv=KFold(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 709 iterations, i.e. alpha=2.001e-03, with an active set of 488 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 709 iterations, i.e. alpha=2.001e-03, with an active set of 488 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 709 iterations, i.e. alpha=2.001e-03, with an active set of 488 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 709 iterations, i.e. alpha=2.001e-03, with an active set of 488 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 709 iterations, i.e. alpha=2.001e-03, with an active set of 488 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 709 iterations, i.e. alpha=2.001e-03, with an active set of 488 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 709 iterations, i.e. alpha=2.001e-03, with an active set of 488 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 395 iterations, i.e. alpha=1.183e-03, with an active set of 265 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 709 iterations, i.e. alpha=2.001e-03, with an active set of 488 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.640e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 128 iterations, i.e. alpha=2.095e-04, with an active set of 105 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=2.065e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=7.576e-03, with an active set of 242 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 617 iterations, i.e. alpha=1.776e-01, with an active set of 452 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.052e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=5.386e-04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 341 iterations, i.e. alpha=6.241e-04, with an active set of 241 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 390 iterations, i.e. alpha=6.673e-04, with an active set of 276 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 547 iterations, i.e. alpha=1.316e-03, with an active set of 380 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.029e-04, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.847e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.871e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.187e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=2.256e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=2.904e-04, with an active set of 156 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 351 iterations, i.e. alpha=3.668e-04, with an active set of 269 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 375 iterations, i.e. alpha=3.753e-04, with an active set of 289 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 37s, sys: 44min 13s, total: 1h 2min 51s\n",
      "Wall time: 4min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.103e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.814e-04, with an active set of 20 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deml = deml.fit(x_train['deml'], y_train['deml'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "deml = deml.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.026e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.007e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=8.859e-04, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "/home/amoffet2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning:\n",
      "\n",
      "Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=7.614e-04, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_test['deml'] = cross_val_predict(deml, x_test['deml'], y_test['deml'], cv=KFold(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Schutt et al\n",
    "Kernel Ridge Regression on Partial Radial Distribution Function (PRDF) representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_schutt = pd.read_pickle(\"./X_prdf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['schutt'], x_test['schutt'], y_train['schutt'], y_test['schutt'] = train_test_split(X_schutt, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build ML model (Kernel Ridge Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "schutt = KernelRidge(kernel='laplacian', alpha=0.001, gamma=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 4min 23s, sys: 5min 37s, total: 5h 10min 1s\n",
      "Wall time: 5h 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "schutt = schutt.fit(x_train['schutt'], y_train['schutt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test['schutt'] = cross_val_predict(schutt, x_test['schutt'], y_test['schutt'], cv=KFold(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we compare these five models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = dict.fromkeys(kernels)\n",
    "for kernel in stats:\n",
    "    stats[kernel] = dict.fromkeys(['r2_score', 'mean_absolute_error', 'mean_squared_error'], 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernel in kernels:\n",
    "    for scorer in ['r2_score', 'mean_absolute_error', 'mean_squared_error']:\n",
    "        stats[kernel][scorer] = (getattr(metrics,scorer)(y_test[kernel], cv_test[kernel]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b02e87147f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 3, sharey=True, sharex=True)\n",
    "\n",
    "ax[0,0].set_xlim([-5, 2])\n",
    "ax[0,0].set_ylim([-5, 2])\n",
    "\n",
    "ax[0,0].set_ylabel(\"Predicted $\\Delta H_{f, atom}$ (eV/atom)\", fontsize=14, y=0.0)\n",
    "ax[1,1].set_xlabel(\"Calculated $\\Delta H_{f, atom}$ (eV/atom)\", fontsize=14)\n",
    "\n",
    "ax[0,0].set_title(\"Faber2015\")\n",
    "ax[0,1].set_title(\"Deml2016\")\n",
    "ax[0,2].set_title(\"Schutt2014\")\n",
    "ax[1,0].set_title(\"Ward2016\")\n",
    "ax[1,1].set_title(\"Ward2017\")\n",
    "\n",
    "ax[0,0].scatter(y_test['faber'], cv_test['faber'], marker='.', color='r')\n",
    "ax[0,1].scatter(y_test['deml'], cv_test['deml'], marker='.', color='g')\n",
    "ax[0,2].scatter(y_test['schutt'], cv_test['schutt'], marker='.', color='b')\n",
    "ax[1,0].scatter(y_test['ward2016'], cv_test['ward2016'], marker='.', color='orange')\n",
    "ax[1,1].scatter(y_test['ward2017'], cv_test['ward2017'], marker='.', color='purple')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        if (i==1 and j==2):\n",
    "            pass\n",
    "        else:\n",
    "            ax[i,j].plot(ax[i,j].get_xlim(), ax[i,j].get_xlim(), 'k--')\n",
    "\n",
    "ax[0,0].text(0.45, 0.03, 'MAE: {:.3f} eV/atom\\nRMSE: {:.3f} eV/atom\\n R2: {:.3f}'.format(stats['faber']['mean_absolute_error'], np.sqrt(stats['faber']['mean_squared_error']), stats['faber']['r2_score']),\n",
    "        transform=ax[0,0].transAxes, fontsize=10,\n",
    "        bbox={'facecolor': 'w', 'edgecolor': 'k'})\n",
    "ax[0,1].text(0.45, 0.03, 'MAE: {:.3f} eV/atom\\nRMSE: {:.3f} eV/atom\\n R2: {:.3f}'.format(stats['deml']['mean_absolute_error'], np.sqrt(stats['deml']['mean_squared_error']), stats['deml']['r2_score']),\n",
    "        transform=ax[0,1].transAxes, fontsize=10,\n",
    "        bbox={'facecolor': 'w', 'edgecolor': 'k'})\n",
    "ax[0,2].text(0.45, 0.03, 'MAE: {:.3f} eV/atom\\nRMSE: {:.3f} eV/atom\\n R2: {:.3f}'.format(stats['schutt']['mean_absolute_error'], np.sqrt(stats['schutt']['mean_squared_error']), stats['schutt']['r2_score']),\n",
    "        transform=ax[0,2].transAxes, fontsize=10,\n",
    "        bbox={'facecolor': 'w', 'edgecolor': 'k'})\n",
    "ax[1,0].text(0.45, 0.03, 'MAE: {:.3f} eV/atom\\nRMSE: {:.3f} eV/atom\\n R2: {:.3f}'.format(stats['ward2016']['mean_absolute_error'], np.sqrt(stats['ward2016']['mean_squared_error']), stats['ward2016']['r2_score']),\n",
    "        transform=ax[1,0].transAxes, fontsize=10,\n",
    "        bbox={'facecolor': 'w', 'edgecolor': 'k'})\n",
    "ax[1,1].text(0.45, 0.03, 'MAE: {:.3f} eV/atom\\nRMSE: {:.3f} eV/atom\\n R2: {:.3f}'.format(stats['ward2017']['mean_absolute_error'], np.sqrt(stats['ward2017']['mean_squared_error']), stats['ward2017']['r2_score']),\n",
    "        transform=ax[1,1].transAxes, fontsize=10,\n",
    "        bbox={'facecolor': 'w', 'edgecolor': 'k'})\n",
    "\n",
    "fig.set_size_inches((12, 7))\n",
    "fig.subplots_adjust(wspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: Composition based features used in Ward 2016 paper seems to predict formation enthalpy best, and the training time is reasonably short as compared to Faber2015 and Schutt2014's methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
